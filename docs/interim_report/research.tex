\chapter{Research}

Before we begin to look at the specific components to be used in this project, we will layout the general line of thought that defined the initial research undertaking. Research on the topic begun by seeking out and talking to a number of students who have previous experience with image processing, this was quite helpful. The resulting suggestions from these conversations formed a good series of starting points to begin with.

One suggested project to consider was OpenCV, an open source computer vision library released under the BSD licence from the Intel Corporation\textsuperscript{\texttrademark}. This library provides implementations of many of the processing algorithms that may be required for the project and is available on both Android and iPhone.

A number of other open source computer vision libraries were also explored such as VTK, Integrating Vision Toolkit and FIJI. But due to issues such as availability on mobile platforms, existing development community and functionality it was decided that OpenCV was the most favourable offering.

Both of the major mobile platforms were discussed and researched but it was thought that with the lack of third-party libraries, the closed nature of the platform and this writers unfamiliarity with development on the iPhone platform, that development progress on the iPhone may be quite slow. Development on the Android platform appears to have a much lower barrier to entry, as its primary development language is Java. Also from studying development and image processing topics it appears to have a quite vibrant development community supporting the platform, which may prove useful later.

At this stage its is important to discover the current state of the art in the area. For object identification in image data, it appears to be an area with much active research but still in the embryonic stages. One impressive application is Google Goggles\textsuperscript{\texttrademark}, an application that enables the user can take a picture of any object and the software will attempt to identify the object in the image e.g. taking a picture of a logo will return a link to the brands website. For well known logos and common physical objects this software is quite successful. But unlike the solution we wish to implement for this project, most of the processing is completed server side.

Another interesting area of study was the architecture of Shazam, a system that records an audio sample on a mobile device, extracts a fingerprint and performs a lookup against remote servers \cite{laplacian09, redcode10}. Although processing audio data instead of image data, this system has many common elements with the architecture being investigated for this project.

\subsection*{Android Platform}
As mentioned earlier in this report, the Google Android platform was chosen due to availability of sufficiently powerful hardware, compatibility with OpenCV for image processing and also ease of development through the use of Java as the programming language.

Google Android is a operating system and software stack, consisting of a modified Linux kernel, a collection of C based libraries offering database, media and 3d graphics to the system and a custom built Java virtual machine called Dalvik. This virtual machine is different to traditional Java VM’s which are traditionally stack based, Dalvik is a register based VM. To execute standard Java classes on the VM \emph{.class} files must be converted to a single Dalvik \emph{.dex}, duplicated data such as strings and constants are removed which helps to conserve space. This conversion process helps to reduce the in memory footprint of an application.

To begin developing an understanding of the platform a number of tutorials and documents on the developer site \url{developer.android.com} were followed, and they proved to be valuable in getting to grips with the platform. 

The larger and important part of the development revolved around the use of OpenCV and the Android NDK. There are a number of active projects maintaining ports of OpenCV for Java, with the most up to date being the “Android-OpenCV” project hosted on Google Code.

\subsection*{OpenCV}
OpenCV is a complete library for processing real-time computer vision, it should be sufficient to provide the main functions necessary for isolating the leaf in the photograph and also to fingerprint the leaf. From reading the documentation it appears that edge detection, Hough transforms and blob analysis/detection are some of the key functions that will be required in the detection of leaf features. Further research and experimentation is necessary in this area.

There are two main stages of image processing required, the identification of the leaf from the background and the detection of features within the leaf.  It maybe possible to integrate these into a single process, which would offer performance gains. 

To enable a leaf’s fingerprint to match other leaves from the same tree it will be necessary that the fingerprints are relative so scale is not a issue. There will also need to be a smoothness factor to ignore certain amounts of damage to a leaf’s edges. Attempting to generate fingerprints so that are general enough to apply to any leaf from a particular tree but specific enough to identify that type of tree will be a challenge. For trees with leaves that change shape over their life if may be necessary to take a number of fingerprints to identify that type of tree. As with any solution like this there will be a certain number of match misses, but it may be possible to develop a ranking mechanism to at least offer the user a list of possible solutions. As stated earlier in this document the ranking mechanism could take location, time of year and previous matches in the area into account to suggest the post probable tree type(s).

Due to limitations discovered in using OpenCV in the Android device emulator, it is not possible without deploying the application to a real handset to experiment with the image processing capability, at this time. It will be necessary to perform the OpenCV development outside the Android framework. A workaround to this is discussed below. 

\subsection*{OpenCV on the desktop}
The OpenCV framework offers bindings for Python and Java among other popular languages. These are perfect for creating prototypes of varying fidelity and using a web-cam as the input device. This will enable quick feedback as to the success or otherwise of a change.

Creating these prototypes in with the Java bindings is probably the best solution. This should enable most code developed in these prototypes to be ported over to the Android application quickly.
